{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/duongnhathuy/A_I/blob/main/Flowers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72bAOzKafKGg"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.callbacks import EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import np_utils\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOI8Bi8xsSr0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "018fa64d-78ec-44b7-d94f-6ebee768a42c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2780 images belonging to 5 classes.\n",
            "Found 694 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "image_generator = ImageDataGenerator(rescale=1./255, validation_split=0.2)    \n",
        "\n",
        "train_dataset = image_generator.flow_from_directory(batch_size=32,\n",
        "                                                 directory='/content/drive/MyDrive/Flowers/train/',\n",
        "                                                 shuffle=True,\n",
        "                                                 target_size=(150, 150), \n",
        "                                                 subset=\"training\",\n",
        "                                                 class_mode='categorical')\n",
        "\n",
        "validation_dataset = image_generator.flow_from_directory(batch_size=32,\n",
        "                                                 directory='/content/drive/MyDrive/Flowers/train/',\n",
        "                                                 shuffle=True,\n",
        "                                                 target_size=(150, 150), \n",
        "                                                 subset=\"validation\",\n",
        "                                                 class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNg0K8mLsXmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5628e2ab-569d-4494-ca60-07c14b48ea92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Daisy': 0, 'Lavender': 1, 'Lily': 2, 'Rose': 3, 'Sunflower': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "train_dataset.classes\n",
        "train_dataset.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qentRntjsZa2"
      },
      "outputs": [],
      "source": [
        "import numpy as np  #\n",
        "import pandas as pd # xu ly mang\n",
        "import seaborn as sns # do thi\n",
        "import matplotlib.pyplot as plt # ve do hoa\n",
        "from sklearn.preprocessing import StandardScaler  # xu ly du lieu , du lieu k dong deu\n",
        "from sklearn.model_selection import train_test_split # chia du lieu \n",
        "from keras.layers import Dense,Activation,Dropout,BatchNormalization,LSTM #  :batch... : chuan cua ANN\n",
        "from keras.models import Sequential #\n",
        "from tensorflow.keras.utils import to_categorical #  de dam bao do hcinh xac cao \n",
        "from keras import callbacks #\n",
        "from sklearn .metrics import  precision_score,recall_score, confusion_matrix, classification_report, accuracy_score,f1_score # thu vien cho do luong"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCgkt-HSscNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d46bd4a2-04e5-42f0-8501-3d609121107a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 128)     3584      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 74, 74, 128)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 32)        36896     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 36, 36, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 41472)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               5308544   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,349,669\n",
            "Trainable params: 5,349,669\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Tạo mô hinh\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "model = Sequential()\n",
        "model.add(Conv2D(128,(3,3),input_shape=(150,150,3),activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(32,(3,3),activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation = 'relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(5,activation ='softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL1esmH-sfRc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import SGD\n",
        "opt = SGD(learning_rate = 0.001, momentum = 0.9)\n",
        "model .compile(optimizer = 'adam', loss ='categorical_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moFkftsdshib",
        "outputId": "cc9ad26f-8d60-47e6-b081-39a3f087f374"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "70/87 [=======================>......] - ETA: 1:38 - loss: 1.6890 - accuracy: 0.3023"
          ]
        }
      ],
      "source": [
        "history=model.fit(train_dataset,batch_size=32,epochs=100,verbose=1,validation_data=validation_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Byw3e9heJjtz"
      },
      "outputs": [],
      "source": [
        "model.save('Flowers.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yn4gWTPesjtZ"
      },
      "outputs": [],
      "source": [
        "# vẽ lại quá trình học\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.legend(['train','Validation'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtXHYuZ9slFV"
      },
      "outputs": [],
      "source": [
        "#in sai so va do chinh xac\n",
        "score = model.evaluate(validation_dataset,verbose=0)\n",
        "print('Sai số : ',score[0])\n",
        "print('Độ chính xác ',score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnFUFJ3Gsmyx"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "import numpy as np\n",
        "filename = \"/content/drive/MyDrive/Flowers/test/Lily/Lily (110).jpeg\"\n",
        "\n",
        "img = load_img(filename,target_size=(150,150))\n",
        "img_show = plt.imshow(img)\n",
        "plt.show()\n",
        "img = img_to_array(img)\n",
        "img = img.reshape(1,150,150,3)\n",
        "img = img.astype('float32')\n",
        "img = img/255\n",
        "kq=np.argmax(model.predict(img),axis=-1)\n",
        "if(kq==0):\n",
        "    print(\"Daisy\")\n",
        "if(kq==1):\n",
        "    print(\"Lavender\")\n",
        "if(kq==2):\n",
        "    print(\"Lily\")\n",
        "if(kq==3):\n",
        "    print(\"Rose\")\n",
        "if(kq==4):\n",
        "    print(\"Sunflower\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "import numpy as np\n",
        "filename = \"/content/drive/MyDrive/Flowers/test/Lily/Lily (110).jpeg\"\n",
        "\n",
        "img = load_img(filename,target_size=(150,150))\n",
        "img_show = plt.imshow(img)\n",
        "plt.show()\n",
        "img = img_to_array(img)\n",
        "img = img.reshape(1,150,150,3)\n",
        "img = img.astype('float32')\n",
        "img = img/255\n",
        "kq=np.argmax(model.predict(img),axis=-1)\n",
        "if(kq==0):\n",
        "    print(\"Daisy\")\n",
        "if(kq==1):\n",
        "    print(\"Lavender\")\n",
        "if(kq==2):\n",
        "    print(\"Lily\")\n",
        "if(kq==3):\n",
        "    print(\"Rose\")\n",
        "if(kq==4):\n",
        "    print(\"Sunflower\")"
      ],
      "metadata": {
        "id": "q2DIm_MwX5V2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}